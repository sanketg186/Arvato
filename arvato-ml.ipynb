{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Arvato Customer segmentation and Classification"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we will work on the following task:\n- Logistic Regression\n- Decision Tree\n- Random Forest\n- AdaBoostClassifier\n- GradientBoostingClassifier\n- XGBoost\n- LGBM"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport lightgbm as lgb\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":22,"outputs":[{"output_type":"stream","text":"/kaggle/input/arvato-cleaned/Customers_cleaned.csv\n/kaggle/input/arvato-cleaned/Azdias_cleaned.csv\n/kaggle/input/arvato-cleaned/Customer_Additional_cleaned.csv\n/kaggle/input/arvato/Udacity_AZDIAS_052018.csv\n/kaggle/input/arvato/Udacity_MAILOUT_052018_TRAIN.csv\n/kaggle/input/arvato/DIAS Attributes - Values 2017.xlsx\n/kaggle/input/arvato/Udacity_MAILOUT_052018_TEST.csv\n/kaggle/input/arvato/Udacity_CUSTOMERS_052018.csv\n/kaggle/input/arvato/DIAS Information Levels - Attributes 2017.xlsx\n/kaggle/input/attribute/attribute_cleaned.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install openpyxl","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting openpyxl\n  Downloading openpyxl-3.0.6-py2.py3-none-any.whl (242 kB)\n\u001b[K     |████████████████████████████████| 242 kB 868 kB/s eta 0:00:01\n\u001b[?25hCollecting jdcal\n  Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\nCollecting et-xmlfile\n  Downloading et_xmlfile-1.0.1.tar.gz (8.4 kB)\nBuilding wheels for collected packages: et-xmlfile\n  Building wheel for et-xmlfile (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-py3-none-any.whl size=8913 sha256=fc7f9f8de9b3c202bd21c6e829a455dc707359e4777790da4fe00a30bff93f04\n  Stored in directory: /root/.cache/pip/wheels/e2/bd/55/048b4fd505716c4c298f42ee02dffd9496bb6d212b266c7f31\nSuccessfully built et-xmlfile\nInstalling collected packages: jdcal, et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-1.0.1 jdcal-1.4.1 openpyxl-3.0.6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the data that we cleaned earlier\ndf_azdias = pd.read_csv('../input/arvato-cleaned/Azdias_cleaned.csv')\ndf_customers = pd.read_csv('../input/arvato-cleaned/Customers_cleaned.csv')\n\n# attribute: contains data about columns description\nignore_unamed_cols = lambda x:'Unnamed' not in x\nattribute = pd.read_excel('../input/arvato/DIAS Attributes - Values 2017.xlsx',header=1,usecols=ignore_unamed_cols\n                         ,engine='openpyxl')\n\n\n# Reading train and test data\ndf_mailout_train = pd.read_csv('../input/arvato/Udacity_MAILOUT_052018_TRAIN.csv',sep=';')\ndf_mailout_test = pd.read_csv('../input/arvato/Udacity_MAILOUT_052018_TEST.csv',sep=';')","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning:\n\nColumns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"attribute.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"  Attribute         Description Value                     Meaning\n0  AGER_TYP  best-ager typology    -1                     unknown\n1       NaN                 NaN     0  no classification possible\n2       NaN                 NaN     1             passive elderly\n3       NaN                 NaN     2            cultural elderly\n4       NaN                 NaN     3   experience-driven elderly","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attribute</th>\n      <th>Description</th>\n      <th>Value</th>\n      <th>Meaning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>-1</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>no classification possible</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>passive elderly</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>cultural elderly</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>experience-driven elderly</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will first scale the data\nscaler = StandardScaler()\nscaler.fit(df_azdias)\ndf_azdias = pd.DataFrame(scaler.transform(df_azdias), columns = df_azdias.columns)\ndf_customers = pd.DataFrame(scaler.transform(df_customers), columns = df_customers.columns)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The below class is used for preprocessing the data\n\nclass DataProcessing:\n    def column_fill(self,df,column_name):\n        '''\n        input\n        df: dataframe\n        column_name: column that need to be filled\n        \n        output\n        df:df filled with values for missing cells\n        '''\n        df[column_name] = df[column_name].ffill()\n        return df\n    \n    def replace_with_nan(self,df,cols):\n        '''\n        Input\n        df: Dataframe\n        cols: columns\n        replacing column values having 'X'or 'XX' with nan\n        output: df\n        '''\n        df[cols] = df[cols].replace({\"X\": np.nan, \"XX\": np.nan})\n        df[cols] = df[cols].astype(float)\n        return df\n    \n    def replace_zero_nan(self,df,cols):\n        '''\n        Input\n        df: Dataframe\n        cols: columns\n        replacing 0 with nan\n        Output\n        df\n        '''\n        df[cols] = df[cols].replace({0: np.nan})\n        df[cols] = df[cols].astype(float)\n        return df\n    \n    def convert_to_date(self,df,cols):\n        '''\n        Input\n        df: dataframe\n        cols:columns\n        desc: convert to date\n        Output\n        df\n        '''\n        df[cols] = pd.to_datetime(df[cols])\n        df[cols] = df[cols].map(lambda x: x.year)\n        return df\n    \n    \n\n    def get_unknown_repr(self,attrib, unknown_attributes_values):\n        '''\n        Input\n        attrib: dataframe\n        unknown_attribute_values: unknown values for attributes\n        \n        Output\n        Returns a list of unknown values\n        '''\n        unknown = unknown_attributes_values[unknown_attributes_values[\"Attribute\"] == attrib][\"Value\"]\n        unknown = unknown.astype(str).str.cat(sep=\",\")\n        unknown = [int(x) for x in unknown.split(\",\")]\n\n        return [unknown]\n    \n    def replace_unknown_with_nan(self,val, unknown):\n        '''\n        Input\n        val:values\n        unknown: list of unknown values\n        Output\n        return nan values in case of unknown values\n        '''\n        if val in unknown:\n            return np.nan\n        else:\n            return val\n        \n    def replace_unknowns(self,df, unknown_attributes_values, verbose=False):\n        '''\n        Input\n        df: dataframe\n        Output\n        Replaces unknown values to 'np.nan' in all the columns provided in unknown_attributes_values list.\n        '''\n        for attrib in unknown_attributes_values.Attribute:\n            unknown = self.get_unknown_repr(attrib, unknown_attributes_values)\n            if verbose:\n                print(\"Replacing {} to NaN in Attribute {}\".format(unknown, attrib))\n            if attrib in df.columns:\n                df[attrib] = df[attrib].apply(self.replace_unknown_with_nan, args=(unknown))\n        return df\n    \n    def get_missing_report(self,df):\n        '''\n        Input\n        df: dataframe\n        Output\n        returns a dataframe with information about column-wise missing values percentages.\n        '''\n        missing_percen = df.isna().sum() * 100/ len(df)\n\n        missing_percen_df = pd.DataFrame({\"Attribute\": df.columns,\n                                         \"Missing_Percentage\": missing_percen}).reset_index(drop=True)\n        return missing_percen_df\n    \n    def remove_columns(self,df, remove_cols):\n        '''\n        Input\n        df: dataframe\n        remove_cols: column list\n        Drops given list of columns from df\n        Output\n        df:dataframe\n        '''\n        df = df.drop(remove_cols, axis = 1)\n        return df\n    \n    def remove_missing_columns(self,df1, df2, df1_missing, df2_missing, threshold=30):\n        '''\n        Input\n        df1: dataframe\n        df2: dataframe\n        df1: dataframe containing columns having missing values above a certain threshold\n        df2: dataframe containing columns having missing values above a certain threshold\n        Output\n        Drops columns from df1 and df2 with given threshold.\n        Uses df1_missing and df2_missing to determing which columns to remove.\n        If df1_missing has more missing columns (missing_percentage > threshold),\n        then df1_missing is taken as reference and vice versa.\n        '''\n\n        removable_cols1 = df1_missing[df1_missing.Missing_Percentage > threshold]\n        removable_cols2 = df2_missing[df2_missing.Missing_Percentage > threshold]\n\n        if len(removable_cols1) > len(removable_cols2):\n            remove_cols = removable_cols1.Attribute.tolist()\n        else:\n            remove_cols = removable_cols2.Attribute.tolist()\n\n        df1 = self.remove_columns(df1, remove_cols)\n        df2 = self.remove_columns(df2, remove_cols)\n        print(f\"\\t\\tRemoved {len(remove_cols)} columns from given dataframes\")\n\n        return (df1, df2, remove_cols)\n    \n    def remove_missing_rows(self,df, threshold, name=\"\"):\n        '''\n        Input\n        df: dataframe\n        threshold: threshold on number of missing features\n        Output\n        Drops rows with number of missing features \n        as per given threshold.\n        '''\n        total_rows = df.shape[0]\n\n        df = df.dropna(thresh=df.shape[1]-threshold)\n\n        removed_rows = total_rows - df.shape[0]\n\n        print(f\"\\t\\tRemoved {removed_rows} rows from {name} dataframe\")\n\n        # Reset index\n        df = df.reset_index()\n        del df['index']\n\n        return df\n    \n    def fix_ost_west_col(self,df):\n        '''\n        Function to label encode the feature \"OST_WEST_KZ\"\n        '''\n        df[\"OST_WEST_KZ\"] = df[\"OST_WEST_KZ\"].replace({\"W\": 0, \"O\": 1})\n\n        return df\n    \n    def fix_anrede_col(self,df):\n        '''\n        Input\n        df:dataframe\n        Output\n        Returns df with label encoding of the feature \"ANREDE_KZ\"\n        '''\n        df[\"ANREDE_KZ\"] = df[\"ANREDE_KZ\"].replace({1: 0, 2: 1})\n\n        return df\n    \n    def fix_cameo_intl_col(self,df):\n        '''\n        Input\n        df: dataframe\n        Output\n        Returns df with  additional columns containing information from 'CAMEO_INTL_2015'\n        '''\n        df['CAMEO_INTL_2015_WEALTH'] = df['CAMEO_INTL_2015'].apply(lambda x: np.floor_divide(float(x), 10) if float(x) else np.nan)\n        df['CAMEO_INTL_2015_FAMILY'] = df['CAMEO_INTL_2015'].apply(lambda x: np.mod(float(x), 10) if float(x) else np.nan)\n\n        df.drop(\"CAMEO_INTL_2015\", axis=1, inplace=True)\n        return df\n    \n    def fix_wohnlage_col(self,df):\n        '''\n        Input\n        df: dataframe\n        Output\n        Returns df after replacing '0' with np.nan from \"WOHNLAGE\" \n        '''\n        df[\"WOHNLAGE\"] = df[\"WOHNLAGE\"].replace({0: np.nan})\n\n        return df\n    \n    def impute_values(self,df,strategy=\"most_frequent\"):\n        '''\n        Input\n        df: dataframe\n        strategy: imutation strategy\n        Output\n        Returns df after imputing values\n        '''\n        imputer = SimpleImputer(strategy=strategy)\n        df = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)\n        return df\n    \n    \n    def map_lp(self,df):\n        '''\n        Input\n        df: dataframe\n        Output\n        Returns df after fixing the LP* columns as LP columns contains lot of redundant information\n        '''\n        convert_1 = {1: 'single', 2: 'couple', 3: 'singleparent', 4: 'singleparent', 5: 'singleparent', \n                  6: 'family', 7: 'family', 8: 'family', 9: 'multihousehold', 10: 'multihousehold', 11: 'multihousehold'}\n        convert_2 = {'single':0, 'couple':1, 'singleparent':2, 'family':3, 'multihousehold':4}\n        df[\"LP_FAMILIE_GROB\"] = df[\"LP_FAMILIE_GROB\"].map(convert_1)\n        df[\"LP_FAMILIE_GROB\"] = df[\"LP_FAMILIE_GROB\"].map(convert_2)\n    \n        # LP_STATUS_GROB    \n        convert_1 = {1: 'lowincome', 2: 'lowincome', 3: 'avgincome', 4: 'avgincome', 5: 'avgincome', \n                      6: 'independant', 7: 'independant', 8: 'houseowner', 9: 'houseowner', 10: 'topearner'}\n        convert_2 = {'lowincome':0, 'avgincome':1, 'independant':2, 'houseowner':3, 'topearner':4}\n\n        df[\"LP_STATUS_GROB\"] = df[\"LP_STATUS_GROB\"].map(convert_1)\n        df[\"LP_STATUS_GROB\"] = df[\"LP_STATUS_GROB\"].map(convert_2)\n\n\n        # LP_LEBENSPHASE_FEIN\n        life_stages = {1: 'younger_age', 2: 'middle_age', 3: 'younger_age',\n                  4: 'middle_age', 5: 'advanced_age', 6: 'retirement_age',\n                  7: 'advanced_age', 8: 'retirement_age', 9: 'middle_age',\n                  10: 'middle_age', 11: 'advanced_age', 12: 'retirement_age',\n                  13: 'advanced_age', 14: 'younger_age', 15: 'advanced_age',\n                  16: 'advanced_age', 17: 'middle_age', 18: 'younger_age',\n                  19: 'advanced_age', 20: 'advanced_age', 21: 'middle_age',\n                  22: 'middle_age', 23: 'middle_age', 24: 'middle_age',\n                  25: 'middle_age', 26: 'middle_age', 27: 'middle_age',\n                  28: 'middle_age', 29: 'younger_age', 30: 'younger_age',\n                  31: 'advanced_age', 32: 'advanced_age', 33: 'younger_age',\n                  34: 'younger_age', 35: 'younger_age', 36: 'advanced_age',\n                  37: 'advanced_age', 38: 'retirement_age', 39: 'middle_age',\n                  40: 'retirement_age'}\n\n        wealth_scale = {1: 'low', 2: 'low', 3: 'average', 4: 'average', 5: 'low', 6: 'low',\n                  7: 'average', 8: 'average', 9: 'average', 10: 'wealthy', 11: 'average',\n                  12: 'average', 13: 'top', 14: 'average', 15: 'low', 16: 'average',\n                  17: 'average', 18: 'wealthy', 19: 'wealthy', 20: 'top', 21: 'low',\n                  22: 'average', 23: 'wealthy', 24: 'low', 25: 'average', 26: 'average',\n                  27: 'average', 28: 'top', 29: 'low', 30: 'average', 31: 'low',\n                  32: 'average', 33: 'average', 34: 'average', 35: 'top', 36: 'average',\n                  37: 'average', 38: 'average', 39: 'top', 40: 'top'}\n\n        df[\"Temp\"] = df[\"LP_LEBENSPHASE_FEIN\"]\n\n        df[\"LP_LEBENSPHASE_FEIN\"] = df[\"LP_LEBENSPHASE_FEIN\"].map(life_stages)\n        df[\"LP_LEBENSPHASE_GROB\"] = df[\"Temp\"].map(wealth_scale)\n\n        life_stages = {'younger_age': 1, 'middle_age': 2, 'advanced_age': 3,\n                'retirement_age': 4}\n        wealth_scale = {'low': 1, 'average': 2, 'wealthy': 3, 'top': 4}\n\n        df[\"LP_LEBENSPHASE_FEIN\"] = df[\"LP_LEBENSPHASE_FEIN\"].map(life_stages)\n        df[\"LP_LEBENSPHASE_GROB\"] = df[\"LP_LEBENSPHASE_GROB\"].map(wealth_scale)\n        return df","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_process = DataProcessing()","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the RESPONSE label distribution across classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_label_count = df_mailout_train['RESPONSE'].value_counts()\ndf_label_count = df_label_count.reset_index()\ndf_label_count.columns = ['label','count']\ntrace1 = go.Bar(x = df_label_count['label'],y = df_label_count['count'],marker=dict(color='#ffdc51'),name='')\nlayout = go.Layout(title = \"Distribution of binary labels\"\n                   ,xaxis=dict(title=\"Labels\"),\n                   yaxis=dict(title=\"Number of data points\"))\nfig = go.Figure(data=[trace1],layout=layout)\niplot(fig)\n","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"0307efd5-a140-4afd-8f01-d0b9beefd03f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0307efd5-a140-4afd-8f01-d0b9beefd03f\")) {                    Plotly.newPlot(                        \"0307efd5-a140-4afd-8f01-d0b9beefd03f\",                        [{\"marker\": {\"color\": \"#ffdc51\"}, \"name\": \"\", \"type\": \"bar\", \"x\": [0, 1], \"y\": [42430, 532]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of binary labels\"}, \"xaxis\": {\"title\": {\"text\": \"Labels\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of data points\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0307efd5-a140-4afd-8f01-d0b9beefd03f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation metric\nAs we can see the class labels are highly imbalanced, so  The usual metric used for imbalanced classification are Precision and Recall or Area under Receiver Operating Curve (AUROC)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fixing Attributes\nattribute =data_process.column_fill(attribute,'Attribute')","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will do the same data processing that we did on azdias and customers dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is a utility function to perform data processing\ndef clean_data(azdias,attribute,df):\n    '''\n    Input\n    azdias: population demographic df\n    attribute: column description df\n    df: dataframe that needs cleaning\n    Output\n    df after performing data cleaning\n    '''\n    warn_cols = list(df.columns[18:20])\n    df = data_process.replace_with_nan(df,warn_cols)\n    cols = [\"LP_FAMILIE_FEIN\", \"LP_FAMILIE_GROB\", \"LP_LEBENSPHASE_FEIN\",\n           \"LP_LEBENSPHASE_GROB\", \"LP_STATUS_FEIN\", \"LP_STATUS_GROB\"]\n    \n    # Fixing LP columns\n    df = data_process.replace_zero_nan(df,cols)\n    \n    # Fixing EINGEFUEGT_AM column\n    df = data_process.convert_to_date(df,'EINGEFUEGT_AM')\n    \n    unknown_attribute_values = attribute[attribute[\"Meaning\"] == \"unknown\"]\n    \n    df = data_process.replace_unknowns(df, unknown_attribute_values)\n    \n    df = data_process.fix_ost_west_col(df)\n    df = data_process.fix_anrede_col(df)\n    df = data_process.fix_cameo_intl_col(df)\n    df = data_process.fix_wohnlage_col(df)\n    \n    remove_cols = [col for col in df.columns if col not in azdias.columns]\n    df = data_process.remove_columns(df, remove_cols)\n    df = data_process.impute_values(df)\n    return df","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df_mailout_train[\"RESPONSE\"]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mailout_train_LNR = df_mailout_train[\"LNR\"]","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data cleaning on training data\ndf_mailout_train = clean_data(df_azdias,attribute,df_mailout_train)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mailout_train.shape","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(42962, 352)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the training data\nscaler = StandardScaler()\ndf_mailout_train = pd.DataFrame(scaler.fit_transform(df_mailout_train), columns = df_mailout_train.columns)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = 22","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating train and validation splits\nX_train, X_val, y_train, y_val = train_test_split(df_mailout_train, labels, stratify=labels, test_size=0.2, random_state=randome_seed)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's clean and scale the testing data also \nmailout_test_LNR = df_mailout_test[\"LNR\"]\ndf_mailout_test = clean_data(df_azdias,attribute,df_mailout_test)\ndf_mailout_test = pd.DataFrame(scaler.transform(df_mailout_test), columns = df_mailout_test.columns)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, X_train, y_train, X_test, y_test):\n    '''\n    Input\n    model: ML model\n    X_train,y_train: training data\n    X_test,y_test: validation data\n    Output\n    Model is trained on training data\n    and \n    accuracy(AUROC score) on validation data and training and validation time is returned \n    '''\n    start = time.time()\n    model = model.fit(X_train, y_train)\n    \n    roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n    \n    end = time.time()\n    time_elapsed = end - start\n    \n    return roc_score, time_elapsed","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [(\"LogisticRegression\", LogisticRegression(random_state=random_seed)),\n          (\"Naive Bayes\", GaussianNB()),\n         (\"DecisionTreeClassifier\", DecisionTreeClassifier(random_state=random_seed)),\n         (\"RandomForestClassifier\", RandomForestClassifier(random_state=random_seed)),\n         (\"GradientBoostingClassifier\", GradientBoostingClassifier(random_state=random_seed)),\n         (\"AdaBoostClassifier\", AdaBoostClassifier(random_state=random_seed)),\n         (\"LGBMClassifier\",lgb.LGBMClassifier(random_state=random_seed)),\n         (\"XGBClassifier\",xgb.XGBClassifier(random_state=random_seed))]","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = {\"Model\":[],\n          \"AUCROC_score\":[],\n          \"Time_in_sec\":[]}\n\nfor name, model in models:\n    roc, time_ = train_model(model, X_train, y_train, X_val, y_val)\n    results[\"Model\"].append(name)\n    results[\"AUCROC_score\"].append(roc)\n    results[\"Time_in_sec\"].append(time_)","execution_count":26,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning:\n\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning:\n\nThe use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n\n","name":"stderr"},{"output_type":"stream","text":"[16:32:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame.from_dict(results, orient='index').transpose()\nresults","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"                        Model AUCROC_score Time_in_sec\n0          LogisticRegression     0.662067    3.745256\n1                 Naive Bayes     0.575640    0.228377\n2      DecisionTreeClassifier     0.502246    2.858840\n3      RandomForestClassifier     0.640842   10.675977\n4  GradientBoostingClassifier     0.784496   56.422587\n5          AdaBoostClassifier     0.751232   12.363351\n6              LGBMClassifier     0.720550    3.823862\n7               XGBClassifier     0.694666   19.612930","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>AUCROC_score</th>\n      <th>Time_in_sec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.662067</td>\n      <td>3.745256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Naive Bayes</td>\n      <td>0.575640</td>\n      <td>0.228377</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier</td>\n      <td>0.502246</td>\n      <td>2.858840</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForestClassifier</td>\n      <td>0.640842</td>\n      <td>10.675977</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.784496</td>\n      <td>56.422587</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.751232</td>\n      <td>12.363351</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LGBMClassifier</td>\n      <td>0.720550</td>\n      <td>3.823862</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>XGBClassifier</td>\n      <td>0.694666</td>\n      <td>19.612930</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now Let's train and tune the models having top 4 best accuracy scores"},{"metadata":{},"cell_type":"markdown","source":"## Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adaboost\nparam_grid = {\"n_estimators\": [20,50,60],\n              \"learning_rate\": [0.01,0.1,0.5,0.9,1.],\n              \"algorithm\":[\"SAMME.R\"]\n              }\n\nadaboost_grid = GridSearchCV(estimator = AdaBoostClassifier(random_state=random_seed), \n                           param_grid = param_grid, \n                           scoring = \"roc_auc\", \n                           cv = 5, n_jobs = -1, verbose=2)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adaboost_grid.fit(X_train, y_train)\n\nbest_adaboost = adaboost_grid.best_estimator_\n\nprint(\"Best Score: \", adaboost_grid.best_score_)\nprint(\"Best Params: \", adaboost_grid.best_params_)","execution_count":30,"outputs":[{"output_type":"stream","text":"Fitting 5 folds for each of 15 candidates, totalling 75 fits\nBest Score:  0.759819560231783\nBest Params:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 50}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_adaboost = best_adaboost.predict_proba(X_val)[:,1]\nprint(\"ROC score on validation data: {:.4f}\".format(roc_auc_score(y_val, preds_adaboost)))","execution_count":31,"outputs":[{"output_type":"stream","text":"ROC score on validation data: 0.7797\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Kaggle submission for adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test_adaboost = best_adaboost.predict_proba(df_mailout_test)[:,1]","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_adaboost = pd.DataFrame(index=mailout_test_LNR, data=preds_test_adaboost)\nkaggle_adaboost.rename(columns={0: \"RESPONSE\"}, inplace=True)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_adaboost.to_csv(\"submission_adaboost.csv\")","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GradientBoosting Classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boost_model = GradientBoostingClassifier(random_state=random_seed)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boost_model.fit(X_train, y_train)\nprint(gradient_boost_model.get_params())","execution_count":45,"outputs":[{"output_type":"stream","text":"{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 22, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_gradient_boost_model = gradient_boost_model.predict_proba(X_val)[:,1]\nprint(\"ROC score on validation data: {:.4f}\".format(roc_auc_score(y_val, preds_gradient_boost_model)))","execution_count":46,"outputs":[{"output_type":"stream","text":"ROC score on validation data: 0.7845\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Kaggle submission for gradient boosting machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test_gradient_boost_model = gradient_boost_model.predict_proba(df_mailout_test)[:,1]","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_gradient_boost_model = pd.DataFrame(index=mailout_test_LNR, data=preds_test_gradient_boost_model)\nkaggle_gradient_boost_model.rename(columns={0: \"RESPONSE\"}, inplace=True)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_gradient_boost_model.to_csv(\"submission_gradient_boost.csv\")","execution_count":49,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LGBMClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_param_grid = {\"max_depth\": [5,10,20],\n              \"learning_rate\": [0.01,0.1,0.5,1.],\n              \"gamma\":[0.1,0.5,1.0],\n              \"n_estimators\":[50,100,150]\n              }\n\nlgb_grid = GridSearchCV(estimator = lgb.LGBMClassifier(objective=\"binary\", \n                                                       boosting_type='gbdt',\n                                                            n_jobs=-1, eval_metric=\"auc\",\n                                                            silent=1,random_state=random_seed), \n                           param_grid = lgb_param_grid, \n                           scoring = \"roc_auc\",\n                           cv = 3, n_jobs = -1, verbose=2)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_grid.fit(X_train,y_train)\nbest_lgb = lgb_grid.best_estimator_\n\nprint(\"Best Score: \", lgb_grid.best_score_)\nprint(\"Best Params: \", lgb_grid.best_params_)","execution_count":61,"outputs":[{"output_type":"stream","text":"Best Score:  0.7562544306286826\nBest Params:  {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_lgb = best_lgb.predict_proba(X_val)[:,1]\nprint(\"ROC score on validation data: {:.4f}\".format(roc_auc_score(y_val, preds_lgb)))","execution_count":62,"outputs":[{"output_type":"stream","text":"ROC score on validation data: 0.7751\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Kaggle submission for lgbm"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test_lgb = best_lgb.predict_proba(df_mailout_test)[:,1]","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_lgb = pd.DataFrame(index=mailout_test_LNR, data=preds_test_lgb)\nkaggle_lgb.rename(columns={0: \"RESPONSE\"}, inplace=True)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_lgb.to_csv(\"submission_lgb.csv\")","execution_count":65,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGB classifier\nxgb_param_grid = {\"max_depth\": [10,20,30],\n              \"learning_rate\": [0.01],\n              \"gamma\":[0.1],\n              \"n_estimators\":[50,100]\n              }\n\nxgb_grid = GridSearchCV(estimator = xgb.XGBClassifier(objective=\"binary:logistic\", \n                                                            n_jobs=-1, eval_metric=\"auc\",\n                                                            silent=1,random_state=random_seed), \n                           param_grid = xgb_param_grid, \n                           scoring = \"roc_auc\",\n                           cv = 3, n_jobs = -1, verbose=2)\n","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_grid.fit(X_train,y_train)\nbest_xgb = xgb_grid.best_estimator_","execution_count":69,"outputs":[{"output_type":"stream","text":"Fitting 3 folds for each of 6 candidates, totalling 18 fits\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning:\n\nThe use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n\n","name":"stderr"},{"output_type":"stream","text":"[17:52:13] WARNING: ../src/learner.cc:541: \nParameters: { silent } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Score: \", xgb_grid.best_score_)\nprint(\"Best Params: \", xgb_grid.best_params_)","execution_count":70,"outputs":[{"output_type":"stream","text":"Best Score:  0.7612332805327325\nBest Params:  {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Kaggle submission for xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test_xgb_grid = best_xgb.predict_proba(df_mailout_test)[:,1]\nkaggle_xgb_grid = pd.DataFrame(index=mailout_test_LNR, data=preds_test_xgb_grid)\nkaggle_xgb_grid.rename(columns={0: \"RESPONSE\"}, inplace=True)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_xgb_grid.to_csv(\"submission_xgb.csv\")","execution_count":72,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}